[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/blog-with-quarto/index.html",
    "href": "posts/blog-with-quarto/index.html",
    "title": "Създаване на блог с quarto",
    "section": "",
    "text": "Създаване на блог за техническа информация с използване на платформата quarto"
  },
  {
    "objectID": "posts/blog-with-quarto/index.html#характеристики",
    "href": "posts/blog-with-quarto/index.html#характеристики",
    "title": "Създаване на блог с quarto",
    "section": "Характеристики:",
    "text": "Характеристики:\n\nпроста и интуитивна предварително зададена структура\nподдържа md синтаксис за въвеждане на текст, заглавия и секции, връзки, картинки, таблици\nподдържа преобразуване на jupyter тетрадки, съдържащи код, формули, графики"
  },
  {
    "objectID": "posts/blog-with-quarto/index.html#основни-стъпки",
    "href": "posts/blog-with-quarto/index.html#основни-стъпки",
    "title": "Създаване на блог с quarto",
    "section": "Основни стъпки:",
    "text": "Основни стъпки:\n\nлокално инсталиране https://quarto.org/docs/get-started/\nгенериране на структурата https://quarto.org/docs/websites/website-blog.html:\n\nотваря се терминал от папката, където ще се съхранява блога и се изпълнява команда:\n quarto create-project myblog --type website:blog\nвизуализира се генерирания блог\n quarto preview myblog\n\nредактират се различните файлове за запознаване със структурата.\n\nЗаглавната страница е във файл index.qmd в коренната директория.\nОбща информация за блога се дава във файл about.qmd в коренната директория\nВсяко съобщение има папка в папка posts и файл index.qmd с основното съдържание. В папката може да има и картинки.\n\nизбира се тема за оформлението на сайта и се задава във файл _quarto.yml:\n\n     format:\n       html:\n         theme: litera\n         css: styles.css\nТемата по подразбиране е cosmo и е със синя заглавна лента. Темата, избрана за този блог е litera с по-убити цветове. Интересна тема е journal, както и много други (cerulean, cyborg, darkly, flatly, lumen, lux, materia, minty, morph, pulse, quartz, sandstone, simplex, sketchy, slate, solar, spacelab, superhero, united, vapor, yeti, zephyr)."
  },
  {
    "objectID": "posts/blog-with-quarto/index.html#публикуване-на-jupyter-тетрадки",
    "href": "posts/blog-with-quarto/index.html#публикуване-на-jupyter-тетрадки",
    "title": "Създаване на блог с quarto",
    "section": "Публикуване на Jupyter тетрадки",
    "text": "Публикуване на Jupyter тетрадки\n\nJust put the notebook in the “posts” folder\nAt the beginning of the jupyter notebook we need to add a cell of type raw with metadata, e.g.\n\n---\ntitle: \"Gradients, broadcasting and backpropagation\"\nauthor: \"me\"\ndate: \"2022-11-20\"\ncategories: [NN]\nformat:\n  html:\n    code-fold: false\njupyter: python3\n---"
  },
  {
    "objectID": "posts/gradients.html",
    "href": "posts/gradients.html",
    "title": "Gradients, broadcasting and backpropagation",
    "section": "",
    "text": "Let’s have \\(y = w \\cdot x + b\\). Application of the rules of differentiation is simple, e.g. \n\\[\\frac{\\mathrm{d}y}{\\mathrm{d}x} = w , \\quad\n\\frac{\\mathrm{d}y}{\\mathrm{d}w} = x, \\quad\n\\frac{\\mathrm{d}y}{\\mathrm{d}b} = 1\\]\nThe change in \\(y\\) is porportional to the change in \\(x\\). The bigger is \\(w\\), the bigger is the change of \\(y\\) for the same change of \\(x\\).\nLet’s \\(L = f(y) = f(y(x))\\). Application of the chain rule is simple, e.g. \n\\[\\frac{\\mathrm{d}L}{\\mathrm{d}x} = \\frac{\\mathrm{d}f(y)}{\\mathrm{d}y} \\cdot \\frac{\\mathrm{d}y}{\\mathrm{d}x} = \\frac{\\mathrm{d}L}{\\mathrm{d}y} \\cdot w\\] \\[\\frac{\\mathrm{d}L}{\\mathrm{d}w} = \\frac{\\mathrm{d}f(y)}{\\mathrm{d}y} \\cdot \\frac{\\mathrm{d}y}{\\mathrm{d}w} = \\frac{\\mathrm{d}L}{\\mathrm{d}y} \\cdot x\\] \\[\\frac{\\mathrm{d}L}{\\mathrm{d}b} = \\frac{\\mathrm{d}f(y)}{\\mathrm{d}y} \\cdot \\frac{\\mathrm{d}y}{\\mathrm{d}b} = \\frac{\\mathrm{d}L}{\\mathrm{d}y} \\cdot 1\\].\nThe multidimensional case is not so simple. Functions with multiple inputs and multiple outputs have multiple partial derivatives which need to be arranged and stored properly. Applying this for batches of data complicates the picture even more.\nThe derivative of a function (transformation \\(\\psi\\)) with multiple inputs \\(\\mathbf{x} \\in \\mathbb{R}^M\\) and multiple outputs \\(\\mathbf{y} \\in \\mathbb{R}^H\\) is a matrix containing the partial derivatives of each output with respect to each input (the so called Jacobian of the transformation, \\(\\frac{\\partial{\\mathbf{y}}}{\\partial{\\mathbf{x}}} \\in \\mathbb{R}^{M \\times H}\\)). For example, if \\(M=4\\) and \\(H=2\\) we can write:\n\\(\\mathbf{y} = \\psi(\\mathbf{x})\\),\n\\(\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ x_4\\end{bmatrix}, \\quad \\mathbf{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\end{bmatrix}\\)\n\\(\\frac{\\partial{\\mathbf{y}}}{\\partial{\\mathbf{x}}} = \\begin{bmatrix} \\frac{\\partial{y_1}}{\\partial{x_1}} & \\frac{\\partial{y_1}}{\\partial{x_2}} & \\frac{\\partial{y_1}}{\\partial{x_3}} & \\frac{\\partial{y_1}}{\\partial{x_4}}\\\\ \\frac{\\partial{y_2}}{\\partial{x_1}} & \\frac{\\partial{y_2}}{\\partial{x_2}} & \\frac{\\partial{y_2}}{\\partial{x_3}} & \\frac{\\partial{y_2}}{\\partial{x_4}} \\end{bmatrix}\\)\nWe should note that in neural networks the input and output features are arranged as raw vectors.\nLet’s have \\(y = x \\cdot W + b\\) and \\(L = f(y)\\)\nwhere\n\n\\(y\\), \\(x\\) and \\(b\\) are row vectors and \\(W\\) is a matrix.\n\\(x\\) includes the \\(m\\) input features\n\\(W\\) is a weight matrix with \\(m\\) rows and \\(h\\) columns;\n\\(b\\) is a bias with \\(h\\) elements;\n\\(y\\) has \\(h\\) features (or nodes).\n\\(x\\) and \\(y\\) represent input and output features (variables, nodes in the NN). Adding additional dimension (multiple rows) could represent multiple data samples. Inputs and outputs could be replaced by matrices \\(X\\) and \\(Y\\) where the last dimension gives the features (\\(x\\) and \\(y\\) for the corresponding data point);\n\n\n\n\nSimple NN\n\n\nThe derivative of \\(\\mathbf{y = A \\cdot x}\\) with respect to \\(\\mathbf{x}\\) is \\(\\mathbf{A}\\).\nThe derivative of \\(\\mathbf{y = x \\cdot A}\\) with respect to \\(\\mathbf{x}\\) is \\(\\mathbf{A^T}\\).\nThe chain rule involves matrix multiplication of Jacobian and vector\nA gradient is attached to each variable and parameter of the model, i.e.\n\\(y.g = \\frac{\\partial{L}}{∂{y}}\\)\n\\(x.g = \\frac{\\partial{L}}{∂{x}} = \\frac{\\partial{L}}{\\partial{y}} \\cdot \\frac{\\partial{y}}{\\partial{x}} = y.g \\cdot \\frac{\\partial{y}}{\\partial{x}} = y.g \\cdot W^T\\)\n\\(b.g = \\frac{\\partial{L}}{∂{b}} = \\frac{\\partial{L}}{\\partial{y}} \\cdot \\frac{\\partial{y}}{\\partial{b}} = y.g \\cdot \\frac{\\partial{y}}{\\partial{b}} = y.g\\)\n\\(W.g = \\partial{L}/∂{W} = ((\\frac{\\partial{L}}{\\partial{y}})^T \\cdot \\frac{\\partial{y}}{\\partial{W}})^T = (y.g^T \\cdot x)^T = x^T \\cdot y.g\\)\nThe shapes of the gradient is the same as the shape of the corresponding variable (parameter), e.g. x.g.shape ≡  x.shape\n\ndef lin_grad(x, w, b, y):\n    b.g = y.g.sum(dim=0)\n    w.g = x.T @ y.g\n    x.g = y.g @ w.T\n\nThe structure of a fully connected neural network with single hidden layer could be represented as follows:\n\n\n\nNN with one hidden layer"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "My notes and clarifications for the fast.ai course 2022p2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Neural Networks",
    "section": "",
    "text": "Gradients, broadcasting and backpropagation\n\n\n\n\n\n\n\nNN\n\n\n\n\n\n\n\n\n\n\n\nNov 23, 2022\n\n\nKrasin Georgiev\n\n\n\n\n\n\n  \n\n\n\n\nСъздаване на блог с quarto\n\n\n\n\n\n\n\nwebtools\n\n\nbg\n\n\n\n\n\n\n\n\n\n\n\nNov 18, 2022\n\n\nme\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nNov 15, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  }
]