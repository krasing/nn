{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Gradients, broadcasting and backpropagation\"\n",
    "author: \"me\"\n",
    "date: \"2022-11-20\"\n",
    "categories: [NN]\n",
    "format:\n",
    "  html:\n",
    "    code-fold: false\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have $y = x \\cdot w + b$. Application of the rules of differentiation is simple, e.g. \n",
    "\n",
    "$$dy/dx = w$$\n",
    "$$dy/dw = x$$\n",
    "$$dy/db = 1$$\n",
    "\n",
    "The change in $y$ is porportional to the change in $x$. The bigger is $w$, the bigger is the change of $y$ for the same change of $x$.\n",
    "\n",
    "Let's $L = f(y) = f(y(x))$. Application of the chain rule is simple, e.g. \n",
    "\n",
    "$$dL/dx = df(y)/dy \\cdot dy/dx = df(y)/dy \\cdot w$$ \n",
    "$$dL/dw = df(y)/dy \\cdot dy/dw = df(y)/dy \\cdot x$$ \n",
    "$$dL/db = df(y)/dy \\cdot dy/db = df(y)/dy \\cdot 1$$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multidimensional case is not so simple. Functions with multiple inputs and multiple outputs have multiple partial derivatives which need to be arranged and stored properly. Applying this for batches of data complicates the picture even more.\n",
    "\n",
    "Let's have $y = x \\cdot W + b$ and $L = f(y)$\n",
    "\n",
    "where \n",
    "\n",
    "- $y$, $x$ and $b$ are row vectors and $W$ is a matrix.\n",
    "- $x$ includes the $m$ input features\n",
    "- $W$ is a weight matrix with $m$ rows and $h$ columns; \n",
    "- $b$ is a bias with $h$ elements; \n",
    "- $y$ has $h$ features (or nodes).\n",
    "- $x$ and $y$ represent input and output features (variables, nodes in the NN). Adding additional dimension (multiple rows) could represent multiple data samples. Inputs and outputs could be replaced by matrices $X$ and $Y$ where the last dimension gives the features ($x$ and $y$ for the corresponding data point); \n",
    "\n",
    "A gradient is attached to each variable and parameter of the model, i.e.\n",
    "\n",
    "$y.g = \\partial{L}/∂{y}$\n",
    "\n",
    "$x.g = \\partial{L}/∂{x} = \\partial{L}/\\partial{y} \\cdot \\partial{y}/\\partial{x} = y.g \\cdot \\partial{y}/\\partial{x} = y.g \\cdot w$\n",
    "\n",
    "$w.g = \\partial{L}/∂{w} = \\partial{L}/\\partial{y} \\cdot \\partial{y}/\\partial{w} = y.g \\cdot \\partial{y}/\\partial{w} = y.g \\cdot x$\n",
    "\n",
    "$b.g = \\partial{L}/∂{b} = \\partial{L}/\\partial{y} \\cdot \\partial{y}/\\partial{b} = y.g \\cdot \\partial{y}/\\partial{b} = y.g$\n",
    "\n",
    "The shapes of the gradient is the same as the shape of the corresponding variable (parameter), e.g. `x.g.shape ≡  x.shape`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Simple NN](../nn-mini.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of a fully connected neural network with single hidden layer could be represented as follows&\n",
    "\n",
    "![NN with one hidden layer](../nn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_grad(x, w, b, y):\n",
    "    b.g = y.g.sum(dim=0)\n",
    "    w.g = x.T @ y.g\n",
    "    x.g =  y.g * w2.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "215.434px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
